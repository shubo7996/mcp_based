{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "219645bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2f29ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core import Settings\n",
    "\n",
    "llm = Ollama(model=\"llama3.2\", request_timeout=120.0)\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35d28fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.mcp import BasicMCPClient, McpToolSpec\n",
    "\n",
    "mcp_client = BasicMCPClient(\"http://127.0.0.1:8000/sse\")\n",
    "mcp_tools = McpToolSpec(client=mcp_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38f5f273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_latest_news \n",
      "    Fetches the latest news headlines from a supported static news source.\n",
      "\n",
      "    This tool currently supports the following sources:\n",
      "    - 'npr'     → National Public Radio\n",
      "    - 'bbc'     → BBC News\n",
      "    Args:\n",
      "        source (str): The news source to fetch headlines from. Must be one of:\n",
      "                    'npr', 'bbc', or 'reuters'. Case-insensitive.\n",
      "\n",
      "    Returns:\n",
      "        str: A plain text string with the top 10 headlines from the selected source,\n",
      "            separated by newlines. If the source is unsupported or an error occurs,\n",
      "            a corresponding message is returned.\n",
      "\n",
      "    Example:\n",
      "        >>> get_latest_news(\"bbc\")\n",
      "    \n",
      "get_wikipedia_summary \n",
      "    Fetches the first paragraph summary of a given topic from Wikipedia.\n",
      "\n",
      "    Parameters:\n",
      "        topic (str): The topic to search for (e.g., \"machine learning\").\n",
      "\n",
      "    Returns:\n",
      "        str: The summary paragraph from the topic's Wikipedia page,\n",
      "             or an error message if not found.\n",
      "\n",
      "    Example:\n",
      "        >>> get_wikipedia_summary(\"Python (programming language)\")\n",
      "    \n",
      "get_stock_news \n",
      "    This function scrapes the latest news headlines (up to 5) from the Finviz stock quote page\n",
      "    and returns them in a human-readable format, each with a timestamp, headline, and URL.\n",
      "\n",
      "    Parameters:\n",
      "        ticker (str): The stock ticker symbol (e.g., \"AAPL\" for Apple Inc.).\n",
      "\n",
      "    Returns:\n",
      "        str: A newline-separated string of the latest headlines in the format:\n",
      "             \"Timestamp - Headline (URL)\".\n",
      "             If an error occurs during the scraping process, returns an error message.\n",
      "\n",
      "    Raises:\n",
      "        This function handles its own exceptions and returns an error message as a string\n",
      "        instead of propagating exceptions.\n",
      "\n",
      "    Example:\n",
      "        >>> get_stock_news(\"GOOGL\")\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "tools = await mcp_tools.to_tool_list_async()\n",
    "for tool in tools:\n",
    "    print(tool.metadata.name, tool.metadata.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719339d8",
   "metadata": {},
   "source": [
    "## System Prompt for Sqlite-Sever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97ca64f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\\\n",
    "You are an AI assistant for Tool Calling.\n",
    "\n",
    "Before you help a user, you need to work with tools to interact with Our Database\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21630b27",
   "metadata": {},
   "source": [
    "## System Prompt for News-Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbc72483",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\\\n",
    "You are an AI assistant with access to these tools:\n",
    "\n",
    "1. Wikipedia Tools:\n",
    "   - get_wikipedia_summary: Get summaries of topics from Wikipedia\n",
    "\n",
    "2. News Tools:\n",
    "   - get_latest_news: Get current news headlines from NPR or BBC\n",
    "\n",
    "3. Stock Tools:\n",
    "   - get_stock_news: Get recent news about specific stocks\n",
    "\n",
    "Use these tools when appropriate to answer user questions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eca87861",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.mcp import McpToolSpec\n",
    "from llama_index.core.agent.workflow import FunctionAgent\n",
    "\n",
    "async def get_agent(tools: McpToolSpec):\n",
    "    tools = await tools.to_tool_list_async()\n",
    "    agent = FunctionAgent(\n",
    "        name=\"Agent\",\n",
    "        description=\"An agent that can work with News Sources.\",\n",
    "        tools=tools,\n",
    "        llm=llm,\n",
    "        system_prompt=SYSTEM_PROMPT,\n",
    "    )\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00a3b853",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent.workflow import (\n",
    "    FunctionAgent, \n",
    "    ToolCallResult, \n",
    "    ToolCall)\n",
    "\n",
    "from llama_index.core.workflow import Context\n",
    "\n",
    "async def handle_user_message(\n",
    "    message_content: str,\n",
    "    agent: FunctionAgent,\n",
    "    agent_context: Context,\n",
    "    verbose: bool = False,\n",
    "):\n",
    "    handler = agent.run(message_content, ctx=agent_context)\n",
    "    async for event in handler.stream_events():\n",
    "        if verbose and type(event) == ToolCall:\n",
    "            print(f\"Calling tool {event.tool_name} with kwargs {event.tool_kwargs}\")\n",
    "        elif verbose and type(event) == ToolCallResult:\n",
    "            print(f\"Tool {event.tool_name} returned {event.tool_output}\")\n",
    "\n",
    "    response = await handler\n",
    "    return str(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c37f178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.mcp import BasicMCPClient, McpToolSpec\n",
    "\n",
    "\n",
    "mcp_client = BasicMCPClient(\"http://127.0.0.1:8000/sse\")\n",
    "mcp_tool = McpToolSpec(client=mcp_client)\n",
    "\n",
    "# get the agent\n",
    "agent = await get_agent(mcp_tool)\n",
    "\n",
    "# create the agent context\n",
    "agent_context = Context(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c40b5fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  get me the latest news from bbc\n",
      "Calling tool get_latest_news with kwargs {'source': 'bbc'}\n",
      "Tool get_latest_news returned meta=None content=[TextContent(type='text', text=\"- Gazans wait for aid as UN says supplies sitting in warehouse despite Israel easing blockade\\n- Canada in talks with US to join Trump's Golden Dome defence system\\n- India's Banu Mushtaq makes history with International Booker win\\n- School bus attack kills at least five in Pakistan\\n- R&B star Chris Brown freed on £5m bail by London court\\n- Canada in talks with US to join Trump's Golden Dome defence system\\n- Six Ukrainian soldiers killed in Russian strike on training exercise\\n- British soldiers make Everest history using new method\\n- An island called Hope is standing up to Beijing in the South China Sea\\n- India's Banu Mushtaq makes history with International Booker win\", annotations=None)] isError=False\n",
      "Agent:  Here are the latest news headlines from BBC:\n",
      "\n",
      "* Gazans wait for aid as UN says supplies sitting in warehouse despite Israel easing blockade\n",
      "* Canada in talks with US to join Trump's Golden Dome defence system\n",
      "* India's Banu Mushtaq makes history with International Booker win\n",
      "* School bus attack kills at least five in Pakistan\n",
      "* R&B star Chris Brown freed on £5m bail by London court\n",
      "User:  showme stock updates of Tesla\n",
      "Calling tool get_stock_news with kwargs {'ticker': 'TSLA'}\n",
      "Tool get_stock_news returned meta=None content=[TextContent(type='text', text=\"Today 08:39AM - Tesla (TSLA) and xAI Expand GPU Buildout Plans (https://finance.yahoo.com/news/tesla-tsla-xai-expand-gpu-123937076.html)\\n08:36AM - Robotaxis could be a game changer for Tesla if Elon Musk can pull it off: WSJ's Tim Higgins (https://www.youtube.com/watch?v=OI00SSZtmKA)\\n08:36AM - McGhee: Tesla trades on optimism, not fundamentals (https://www.youtube.com/watch?v=rEMxFiEDSwE)\\n08:36AM - Bousta: Tesla is going back to its roots with products that customers truly love (https://www.youtube.com/watch?v=SJJOTCE-7CU)\\n08:23AM - Tesla Is Entering a 'Golden Era,' Says Ives (https://finance.yahoo.com/video/tesla-entering-golden-era-says-122352223.html)\", annotations=None)] isError=False\n",
      "Agent:  Here are the latest stock updates for Tesla:\n",
      "\n",
      "* Tesla and xAI Expand GPU Buildout Plans\n",
      "* Robotaxis could be a game changer for Tesla if Elon Musk can pull it off: WSJ's Tim Higgins\n",
      "* McGhee: Tesla trades on optimism, not fundamentals\n",
      "* Bousta: Tesla is going back to its roots with products that customers truly love\n",
      "* Tesla Is Entering a 'Golden Era,' Says Ives\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"Enter your message: \")\n",
    "    if user_input == \"exit\":\n",
    "        break\n",
    "    print(\"User: \", user_input)\n",
    "    response = await handle_user_message(user_input, agent, agent_context, verbose=True)\n",
    "    print(\"Agent: \", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
